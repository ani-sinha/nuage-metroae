- name: Get vsd node(s) information
  import_role:
    name: common
    tasks_from: vsd-node-info.yml
  vars:
    vsd_hostname: "{{ vsd_fqdn }}"
  run_once: true

- block:

  - name: Disable shard allocation
    uri:
      url: "{{ disable_shard_url }}"
      method: PUT
      headers:
        Content-Type: "application/json"
      body: "{{ lookup('file', 'disable_shard.json') }}"
      body_format: json
      timeout: 300

  - name: Perform sync flush
    command:
      cmd: "curl -XPOST 'localhost:9200/_flush/synced?pretty'"
      warn: false

  run_once: true
  when: vstat_sa_or_ha is match('ha')

- name: Disable elasticsearch serivce
  service:
    name: elasticsearch
    state: stopped

- name: Copy upgrade bundle to vstat node(s)
  copy: src={{ vstat_upgrade_scripts_path }}/{{ vstat_upgrade_scripts_file }}
          dest=/root/
          mode=0700

- name: Execute upgrade script
  shell: "/root/{{ vstat_upgrade_scripts_file }}"

- block:
  - name: Figure out Active ES cluster
    shell: crontab -l
    register: crontabOutput
    ignore_errors: true

  - name: Skip execute VSD script for backup vstat
    set_fact:
      run_command_on_vsd: false
    when: crontabOutput.stdout.find("curator_snapshot") == -1

  - name: Update elasticsearch config file
    lineinfile:
      line: 'path.repo: ["/mnt/nfs/backup"]'
      path: /etc/elasticsearch/elasticsearch.yml

  - name: Restart elastic search
    service:
      name: elasticsearch
      state: restarted

  - name: Check to see if elasticsearch restarted
    command: systemctl status elasticsearch
    register: status
    until: status.stdout.find("active (running)") != -1
    retries: 5
    delay: 10

  - name: Wait for elasticsearch ports
    wait_for:
      port: 9200
      delay: 10

  when:
    - groups['primary_vstats'] is defined
    - groups['backup_vstats'] is defined

- name: Check indices health before migration
  check_url_response_in_each_line:
    url: "{{ indicies_health_url }}"
    search_string: "green"
    timeout_seconds: 300
    test_interval_seconds: 30
  run_once: true

- block:
  - name: Execute VSTAT standalone script
    import_tasks: execute_sa_script.yml
    run_once: true

  rescue:
    - name: Wait for shard count go down to zero and status to turn green
      import_tasks: get_health_status.yml
      run_once: true

    - name: Check ES Status
      fail: msg="Elasticsearch upgrade failed, status is not green"
      when: es_status.json.status != 'green'

    - name: Check ES Unassigned Shards
      fail: msg="Elasticsearch upgrade failed, unassigned_shards != 0"
      when: es_health.json.unassigned_shards != 0

    - name: Execute VSTAT standalone script after status turns green
      import_tasks: execute_sa_script.yml
      run_once: true

  when:
    - vstat_sa_or_ha is match('sa')
    - run_command_on_vsd | default(true)

- block:
  - name: Execute VSTAT clustered script
    import_tasks: execute_ha_script.yml
    delegate_to: "{{ vsd_hostname_list[0] }}"
    run_once: true

  rescue:
    - name: Wait for shard count go down to zero and status to turn green
      import_tasks: get_health_status.yml
      run_once: true

    - name: Check ES Status
      fail: msg="Elasticsearch upgrade failed, status is not green"
      when: es_status.json.status != 'green'

    - name: Check ES Unassigned Shards
      fail: msg="Elasticsearch upgrade failed, unassigned_shards != 0"
      when: es_health.json.unassigned_shards != 0

    - name: Execute VSTAT clustered script after status turns green
      import_tasks: execute_ha_script.yml
      run_once: true

  when:
    - vstat_sa_or_ha is match('ha')
    - run_command_on_vsd | default(true)

- name: Get ES version
  uri:
    url: "{{ version_url }}"
    method: GET
  register: es_version
  run_once: true

- block:

  - name: Assert that we are running ES version 6.7.0
    assert:
      that: es_version.json.version.number is version('6.7.0', '==')
      msg: Expecting ES version 6.7.0, found ES version "{{ es_version.json.version.number }}, quitting."

  - name: Check nodes status for ES cluster
    uri:
      url: "{{ nodes_url }}"
      method: GET
    register: nodes_output
    run_once: true

  - name: Check indices health before migration
    check_url_response_in_each_line:
      url: "{{ indicies_health_url }}"
      search_string: "green"
      timeout_seconds: 300
      test_interval_seconds: 30
    run_once: true

  - name: Migrate old indicies to new ones
    command: "{{ index_migrate_cmd }}"
    run_once: true

  - name: Check recovery health
    check_url_response_in_each_line:
      url: "{{ recovery_health_url }}"
      search_string: "done"
      timeout_seconds: 300
      test_interval_seconds: 30
    run_once: true

  - name: Check indices health after migration
    check_url_response_in_each_line:
      url: "{{ indicies_health_url }}"
      search_string: "green"
      timeout_seconds: 300
      test_interval_seconds: 30
    run_once: true


  when: upgrade_to_version is version('6.0.1', '>=')

- block:

  - name: Assert that we are running ES version 5.5.0
    assert:
      that: es_version.json.version.number is version('5.5.0', '==')
      msg: Expecting ES version 5.5.0, found ES version "{{ es_version.json.version.number }}, quitting."

  when: upgrade_to_version is version('6.0.1', '<')


- name: Restart Elasticsearch service
  service:
    name: elasticsearch
    state: restarted


    -07-31T16:30:32,712][INFO ][o.e.h.n.Netty4HttpServerTransport] [8x9mnXV] publish_address {192.168.122.131:9200}, bound_addresses {[::1]:9200}, {127.0.0.1:9200}, {192.168.122.131:9200}, {[fe80::5054:ff:fe69:aa83]:9200}
[2019-07-31T16:30:32,713][INFO ][o.e.n.Node               ] [8x9mnXV] started
[2019-07-31T16:30:32,877][INFO ][o.e.c.s.ClusterSettings  ] [8x9mnXV] updating [cluster.routing.allocation.enable] from [all] to [none]
[2019-07-31T16:30:32,897][WARN ][o.e.r.f.FsRepository     ] [8x9mnXV] The specified location [/mnt/nfs/backup] should start with a repository path specified by the path.repo setting, but the path.repo setting was not set on this node
[2019-07-31T16:30:32,903][WARN ][o.e.r.RepositoriesService] [8x9mnXV] failed to create repository [fs][test]
org.elasticsearch.repositories.RepositoryException: [test] location [/mnt/nfs/backup] doesn't match any of the locations specified by path.repo because this setting is empty
        at org.elasticsearch.repositories.fs.FsRepository.<init>(FsRepository.java:98) ~[elasticsearch-6.7.0.jar:6.7.0]
        at org.elasticsearch.repositories.RepositoriesModule.lambda$new$0(RepositoriesModule.java:50) ~[elasticsearch-6.7.0.jar:6.7.0]
        at org.elasticsearch.repositories.Repository$Factory.create(Repository.java:70) ~[elasticsearch-6.7.0.jar:6.7.0]
        at org.elasticsearch.repositories.RepositoriesService.createRepository(RepositoriesService.java:413) ~[elasticsearch-6.7.0.jar:6.7.0]
        at org.elasticsearch.repositories.RepositoriesService.applyClusterState(RepositoriesService.java:334) ~[elasticsearch-6.7.0.jar:6.7.0]
        at org.elasticsearch.cluster.service.ClusterApplierService.lambda$callClusterStateAppliers$6(ClusterApplierService.java:484) ~[elasticsearch-6.7.0.jar:6.7.0]
        at java.lang.Iterable.forEach(Iterable.java:75) [?:1.8.0_191]
        at org.elasticsearch.cluster.service.ClusterApplierService.callClusterStateAppliers(ClusterApplierService.java:481) [elasticsearch-6.7.0.jar:6.7.0]
        at org.elasticsearch.cluster.service.ClusterApplierService.applyChanges(ClusterApplierService.java:468) [elasticsearch-6.7.0.jar:6.7.0]
        at org.elasticsearch.cluster.service.ClusterApplierService.runTask(ClusterApplierService.java:419) [elasticsearch-6.7.0.jar:6.7.0]
        at org.elasticsearch.cluster.service.ClusterApplierService$UpdateTask.run(ClusterApplierService.java:163) [elasticsearch-6.7.0.jar:6.7.0]
        at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) [elasticsearch-6.7.0.jar:6.7.0]
        at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252) [elasticsearch-6.7.0.jar:6.7.0]
        at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215) [elasticsearch-6.7.0.jar:6.7.0]
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_191]
:
